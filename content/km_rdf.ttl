@prefix article: <http://ogp.me/ns/article#> .
@prefix bibo: <http://purl.org/ontology/bibo/> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix dc1: <http://purl.org/dc/terms/> .
@prefix fb: <http://ogp.me/ns/fb#> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix ns1: <twitter:> .
@prefix og: <http://ogp.me/ns#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix schema: <http://schema.org/> .
@prefix sioc: <http://rdfs.org/sioc/ns#> .
@prefix void: <http://rdfs.org/ns/void#> .
@prefix xml: <http://www.w3.org/XML/1998/namespace> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

<file:///home/jacob/Blog/content/authors/bram.ttl#BramSteenwinckel> a foaf:Person ;
    foaf:account <https://github.com/bsteenwi/>,
        <https://twitter.com/BSteenwinckel>,
        <https://www.linkedin.com/in/bram-steenwinckel-557069147/> ;
    foaf:depiction <https://avatars0.githubusercontent.com/u/9083494> ;
    foaf:familyName "Steenwinckel" ;
    foaf:givenName "Bram" ;
    foaf:interest "Anomaly Detection",
        "Root Cause Analysis" ;
    foaf:mbox <mailto:bram.steenwinckel@ugent.be> ;
    foaf:name "Bram Steenwinckel" .

<file:///home/jacob/Blog/content/authors/femkeo.ttl#FemkeOngenae> a foaf:Person ;
    owl:sameAs <https://data.verborgh.org/people/femke_ongenae> ;
    foaf:account <https://biblio.ugent.be/person/802000192218>,
        <https://github.com/fongenae>,
        <https://scholar.google.be/citations?user=ezkNNF4AAAAJ&hl=nl>,
        <https://twitter.com/fongenae>,
        <https://www.linkedin.com/in/femke-ongenae-10b2587/> ;
    foaf:depiction <file:///home/jacob/Blog/content/authors/broken> ;
    foaf:familyName "Ongenae" ;
    foaf:givenName "Femke" ;
    foaf:interest "Agile Development",
        "Anomaly Detection",
        "Data Analytics",
        "Decision Support Systems",
        "Grant Coordination",
        "Internet of Things",
        "Machine Learning",
        "Medical Informatics",
        "Multidisciplinary Research",
        "Ontology",
        "Predictive Analytics",
        "Project Management",
        "Root Cause Analysis",
        "SCRUM",
        "Semantic Web",
        "Stream Reasoning",
        "White-Box Machine Learning",
        "eHealth" ;
    foaf:mbox <mailto:femke.ongenae@ugent.be> ;
    foaf:name "Femke Ongenae" .

<file:///home/jacob/Blog/content/authors/gilles.ttl#GillesVandewiele> a foaf:Person ;
    owl:sameAs <https://data.verborgh.org/people/gilles_vandewiele> ;
    foaf:account <https://github.com/GillesVandewiele>,
        <https://twitter.com/gillesvdwiele>,
        <https://www.linkedin.com/in/gillesvandewiele> ;
    foaf:depiction <http://users.ugent.be/~givdwiel/img/profielfoto.jpg> ;
    foaf:familyName "Vandewiele" ;
    foaf:givenName "Gilles" ;
    foaf:homepage <http://users.ugent.be/~givdwiel> ;
    foaf:interest "Decision Support Systems",
        "White-Box Machine Learning" ;
    foaf:mbox <mailto:gilles.vandewiele@ugent.be> ;
    foaf:name "Gilles Vandewiele" .

<file:///home/jacob/Blog/content/authors/jelle.ttl#JelleDeBock> a foaf:Person ;
    foaf:account <https://github.com/jelledebock>,
        <https://twitter.com/JelleDeBock>,
        <https://www.linkedin.com/in/jelle-de-bock-670a7090/> ;
    foaf:depiction "jelle.jpg" ;
    foaf:familyName "De Bock" ;
    foaf:givenName "Jelle" ;
    foaf:interest "Data processing and analytics" ;
    foaf:mbox <mailto:jelle.debock@ugent.be> ;
    foaf:name "Jelle De Bock" .

<file:///home/jacob/Blog/content/authors/mathias.ttl#MathiasDeBrouwer> a foaf:Person ;
    foaf:account <https://github.com/mrdbrouw>,
        <https://twitter.com/mathiasdbr>,
        <https://www.linkedin.com/in/mathiasdebrouwer/> ;
    foaf:depiction <https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAIA_wDGAAAAAQAAAAAAAAtsAAAAJGNhMWUwMTc1LTM4OTctNDc0NC04YjUwLTZhZDgzZDljNmJhNg.jpg> ;
    foaf:familyName "De Brouwer" ;
    foaf:givenName "Mathias" ;
    foaf:interest "Edge Computing",
        "Stream Reasoning" ;
    foaf:mbox <mailto:mrdbrouw.debrouwer@ugent.be> ;
    foaf:name "Mathias De Brouwer" .

<file:///home/jacob/Blog/content/authors/pieter.ttl#PieterBonte> a foaf:Person ;
    foaf:account <https://github.com/pbonte/>,
        <https://twitter.com/psbonte>,
        <https://www.linkedin.com/in/pieter-bonte-9294315a> ;
    foaf:depiction "pieter.jpg" ;
    foaf:familyName "Bonte" ;
    foaf:givenName "Pieter" ;
    foaf:interest "Stream Reasoning" ;
    foaf:mbox <mailto:pieter.bonte@ugent.be> ;
    foaf:name "Pieter Bonte" .

<file:///home/jacob/Blog/content/authors/stijn.ttl#StijnVerstichel> a foaf:Person ;
    foaf:account <https://be.linkedin.com/in/stijn-verstichel-3202015>,
        <https://github.com/svrstich/>,
        <https://twitter.com/svrstich> ;
    foaf:depiction <https://www.ugent.be/ea/img/idlab/members/stijnverstichel-jpg/@@images/744c237f-5a8f-4a7b-829b-4209233551b0.jpeg> ;
    foaf:familyName "Verstichel" ;
    foaf:givenName "Stijn" ;
    foaf:interest "Distributed Reasoning for Fault Detection and Diagnosis" ;
    foaf:mbox <mailto:stijn.verstichel@ugent.be> ;
    foaf:name "Stijn Verstichel" .

<file:///publications/8541801/> a schema:WebPage ;
    og:description "Continuous person monitoring systems usually assume singleperson households. Presence of visitors, such as family members and friends, and multi-person households are therefore not taken into consideration, although they can still influence results. However, in order to reason about a specific monitored person’s evolution and trends, it is needed to accurately recognise the different activities that these persons perform throughout a day. This paper considers multi-person households and focuses on the problem of assigning activities detected by a continuous monitoring system to the person that has performed these activities. The proposed solution consists of modelling the domain terminology into an ontology, as well as that person’s typical habits by means of a Finite State Machine – represented in its own ontology – using the concepts from the domain ontology. Sequences of recognized activities are then compared to the Finite State Machines associated to the different persons in a household, and assigned to the person with the most similar modelled sequence."@en ;
    og:title "Attributing recognised activities in multi-person households using ontology-based finite state machines"@en ;
    og:type "article"@en ;
    og:url "/publications/8541801/"@en ;
    dc1:title "Attributing recognised activities in multi-person households using ontology-based finite state machines"@en ;
    schema:about <file:///publication/8541801> ;
    schema:isPartOf <file:///> ;
    schema:mainEntity <file:///publication/8541801> .

<file:///publications/8550825/> a schema:WebPage ;
    og:description "In 2013, the Flemish Government launched the Vitalink platform. This initiative focuses on the sharing of health and welfare data to support primary healthcare. In this paper, the objectives and mission of the Vitalink initiative are discussed. Security and privacy measures are reviewed, and the technical implementation of the Vitalink platform is presented. Through a case study, the possibility of interaction with cloud solutions for healthcare is also investigated upon; this was initially not the focus of Vitalink. The Vitalink initiative provides support for secure data sharing in primary healthcare, which in the long term will improve the efficiency of care and will decrease costs. Based on the results of the case study, Vitalink allowed cloud solutions or applications not providing end-to-end security to use their system. The most important lesson learned during this research was the need for firm regulations and stipulations for cloud solutions to interact with the Vitalink platform. However, these are currently still vague."@en ;
    og:title "Sharing health data in Belgium: A home care case study using the Vitalink platform"@en ;
    og:type "article"@en ;
    og:url "/publications/8550825/"@en ;
    dc1:title "Sharing health data in Belgium: A home care case study using the Vitalink platform"@en ;
    schema:about <file:///publication/8550825> ;
    schema:isPartOf <file:///> ;
    schema:mainEntity <file:///publication/8550825> .

<file:///publications/ONGENAE20137629/> a schema:WebPage ;
    og:description "Context-aware platforms consist of dynamic algorithms that take the context information into account to adapt the behavior of the applications. The relevant context information is modeled in a context model. Recently, a trend has emerged towards capturing the context in an ontology, which formally models the concepts within a certain domain, their relations and properties.Although much research has been done on the subject, the adoption of context-aware services in healthcare is lagging behind what could be expected. The main complaint made by users is that they had to significantly alter workflow patterns to accommodate the system. When new technology is introduced, the behavior of the users changes to adapt to it. Moreover, small differences in user requirements often occur between different environments where the application is deployed. However, it is difficult to foresee these changes in workflow patterns and requirements at development time. Consequently, the context-aware applications are not tuned towards the needs of the users and they are required to change their behavior to accommodate the technology instead of the other way around.To tackle this issue, a self-learning, probabilistic, ontology-based framework is proposed, which allows context-aware applications to adapt their behavior at run-time. It exploits the context information gathered in the ontology to mine for trends and patterns in the behavior of the users. These trends are then prioritized and filtered by associating probabilities, which express their reliability. This new knowledge and their associated probabilities are then integrated into the context model and dynamic algorithms. Finally, the probabilities are in- or decreased, according to context and behavioral information gathered about the usage of the learned information.A use case is presented to illustrate the applicability of the framework, namely mining the reasons for patients’ nurse call light use to automatically launch calls. Detecting Systemic Inflammatory Response Syndrome (SIRS) as a reason for nurse calls is used as a realistic scenario to evaluate the correctness and performance of the proposed framework. It is shown that correct results are achieved when the dataset contains at least 1000 instances and the amount of noise is lower than 5%. The execution time and memory usage are also negligible for a realistic dataset, i.e., below 100 ms and 10 MB."@en ;
    og:title "A probabilistic ontology-based platform for self-learning context-aware healthcare applications"@en ;
    og:type "article"@en ;
    og:url "/publications/ONGENAE20137629/"@en ;
    dc1:title "A probabilistic ontology-based platform for self-learning context-aware healthcare applications"@en ;
    schema:about <file:///publication/ONGENAE20137629> ;
    schema:isPartOf <file:///> ;
    schema:mainEntity <file:///publication/ONGENAE20137629> .

<file:///publications/arndt_ai4health_2018/> a schema:WebPage ;
    og:description "Modern developments confront us with an ever increasing amount of streaming data: different sensors in environments like hospitals or factories communicate their measurements to other applications. Having this data at disposal faces us with a new challenge: the data needs to be integrated to existing frameworks. As the availability of sensors can rapidly change, these need to be flexible enough to easily incorporate new systems without having to be explicitly configured. Semantic Web applications offer a solution for that enabling computers to ‘understand’ data. But for them the pure amount of data and different possible queries which can be performed on it can form an obstacle. This paper tackles this problem: we present a formalism to describe stream queries in the ontology context in which they might become relevant. These descriptions enable us to automatically decide based on the actual setting and the problem to be solved which and how sensors should be monitored further. This helps us to limit the streaming data taken into account for reasoning tasks and make stream reasoning more performant. We illustrate our approach on a health-care use case where different sensors are used to measure data on patients and their surrounding in a hospital."@en ;
    og:title "SENSdesc: Connect Sensor queries and Context"@en ;
    og:type "article"@en ;
    og:url "/publications/arndt_ai4health_2018/"@en ;
    dc1:title "SENSdesc: Connect Sensor queries and Context"@en ;
    schema:about <file:///publication/arndt_ai4health_2018> ;
    schema:isPartOf <file:///> ;
    schema:mainEntity <file:///publication/arndt_ai4health_2018> .

<file:///publications/bonte2017massif/> a schema:WebPage ;
    og:description "Internet of Things (IoT), data-producing entities sense their environment and transmit these observations to a data processing platform for further analysis. Applications can have a notion of context awareness by combining this sensed data, or by processing the combined data. The processes of combining data can consist both of merging the dynamic sensed data, as well as fusing the sensed data with background and historical data. Semantics can aid in this task, as they have proven their use in data integration, knowledge exchange and reasoning. Semantic services performing reasoning on the integrated sensed data, combined with background knowledge, such as profile data, allow extracting useful information and support intelligent decision making. However, advanced reasoning on the combination of this sensed data and background knowledge is still hard to achieve. Furthermore, the collaboration between semantic services allows to reach complex decisions. The dynamic composition of such collaborative workflows that can adapt to the current context, has not received much attention yet. In this paper, we present MASSIF, a data-driven platform for the semantic annotation of and reasoning on IoT data. It allows the integration of multiple modular reasoning services that can collaborate in a flexible manner to facilitate complex decision-making processes. Data-driven workflows are enabled by letting services specify the data they would like to consume. After thorough processing, these services can decide to share their decisions with other consumers. By defining the data these services would like to consume, they can operate on a subset of data, improving reasoning efficiency. Furthermore, each of these services can integrate the consumed data with background knowledge in its own context model, for rapid intelligent decision making. To show the strengths of the platform, two use cases are detailed and thoroughly evaluated."@en ;
    og:title "The MASSIF platform: a modular and semantic platform for the development of flexible IoT services"@en ;
    og:type "article"@en ;
    og:url "/publications/bonte2017massif/"@en ;
    dc1:title "The MASSIF platform: a modular and semantic platform for the development of flexible IoT services"@en ;
    schema:about <file:///publication/bonte2017massif> ;
    schema:isPartOf <file:///> ;
    schema:mainEntity <file:///publication/bonte2017massif> .

<file:///publications/taxidou_dapd_2018/> a schema:WebPage ;
    og:description "Fast, massive, and viral data diffused on social media affects a large share of the online population, and thus, the (prospective) information diffusion mechanisms behind it are of great interest to researchers. The (retrospective) provenance of such data is equally important because it contributes to the understanding of the relevance and trustworthiness of the information…"@en ;
    og:title "Web-scale Provenance Reconstruction of Implicit Information Diffusion on Social Media"@en ;
    og:type "article"@en ;
    og:url "https://ruben.verborgh.org/publications/taxidou_dapd_2018/"@en ;
    dc1:title "Web-scale Provenance Reconstruction of Implicit Information Diffusion on Social Media"@en ;
    void:inDataset <https://data.verborgh.org/ruben#dataset> ;
    schema:about <https://dx.doi.org/10.1007/s10619-017-7211-3> ;
    schema:author <https://ruben.verborgh.org/profile/#me> ;
    schema:isPartOf <file:///#site> ;
    schema:mainEntity <https://dx.doi.org/10.1007/s10619-017-7211-3> ;
    schema:publisher <https://ruben.verborgh.org/profile/#me> ;
    ns1:card "summary"@en ;
    ns1:site "@RubenVerborgh"@en .

<file:///publications/vandewiele_genesim_2016/> a schema:WebPage ;
    og:description "Models obtained by decision tree induction techniques excel in being interpretable. However, they can be prone to overfitting, which results in a low predictive performance. Ensemble techniques are able to achieve a higher accuracy. However, this comes at a cost of losing interpretability of the resulting model. This makes ensemble techniques impractical in applications where decision support, instead of decision making, is crucial. To bridge this gap, we present the GENESIM algorithm that transforms an ensemble of decision trees to a single decision tree with an enhanced predictive performance by using a genetic algorithm. We compared GENESIM to prevalent decision tree induction and ensemble techniques using twelve publicly available data sets. The results show that GENESIM achieves a better predictive performance on most of these data sets than decision tree induction techniques and a predictive performance in the same order of magnitude as the ensemble techniques. Moreover, the resulting model of GENESIM has a very low complexity, making it very interpretable, in contrast to ensemble techniques."@en ;
    og:title "GENESIM : genetic extraction of a single, interpretable model"@en ;
    og:type "article"@en ;
    og:url "/publications/vandewiele_genesim_2016/"@en ;
    dc1:title "GENESIM : genetic extraction of a single, interpretable model"@en ;
    schema:about <file:///publication/vandewiele_genesim_2016> ;
    schema:isPartOf <file:///> ;
    schema:mainEntity <file:///publication/vandewiele_genesim_2016> .

<file:///#site> a schema:WebSite ;
    schema:about <https://ruben.verborgh.org/profile/#me> ;
    schema:author <https://ruben.verborgh.org/profile/#me> ;
    schema:publisher <https://ruben.verborgh.org/profile/#me> .

<file:///publication/8541801> a schema:ScholarlyArticle,
        foaf:Document ;
    dc1:creator _:N003dd7b9fdf84347a3a4edaeff755e6a,
        _:N3c59b1bfc8c74f60b4fcc0f53a0bb97c,
        _:N92f755d8ec69429aa810dcc8d1fd0d94,
        _:Nd40d6f8d3b8b485baa65d82645bd0a5f,
        _:Ndcafa4ed27044680a470e415cca914e7,
        <file:///author/femke-ongenae>,
        <file:///author/stijn-verstichel> ;
    dc1:description """
                Continuous person monitoring systems usually assume singleperson households. Presence of visitors, such as family members and friends, and multi-person households are therefore not taken into consideration, although they can still influence results. However, in order to reason about a specific monitored person’s evolution and trends, it is needed to accurately recognise the different activities that these persons perform throughout a day. This paper considers multi-person households and focuses on the problem of assigning activities detected by a continuous monitoring system to the person that has performed these activities. The proposed solution consists of modelling the domain terminology into an ontology, as well as that person’s typical habits by means of a Finite State Machine – represented in its own ontology – using the concepts from the domain ontology. Sequences of recognized activities are then compared to the Finite State Machines associated to the different persons in a household, and assigned to the person with the most similar modelled sequence.
            """@en ;
    dc1:title "Attributing recognised activities in multi-person households using ontology-based finite state machines"@en ;
    schema:author _:N003dd7b9fdf84347a3a4edaeff755e6a,
        _:N3c59b1bfc8c74f60b4fcc0f53a0bb97c,
        _:N92f755d8ec69429aa810dcc8d1fd0d94,
        _:Nd40d6f8d3b8b485baa65d82645bd0a5f,
        _:Ndcafa4ed27044680a470e415cca914e7,
        <file:///author/femke-ongenae>,
        <file:///author/stijn-verstichel> ;
    schema:description """
                Continuous person monitoring systems usually assume singleperson households. Presence of visitors, such as family members and friends, and multi-person households are therefore not taken into consideration, although they can still influence results. However, in order to reason about a specific monitored person’s evolution and trends, it is needed to accurately recognise the different activities that these persons perform throughout a day. This paper considers multi-person households and focuses on the problem of assigning activities detected by a continuous monitoring system to the person that has performed these activities. The proposed solution consists of modelling the domain terminology into an ontology, as well as that person’s typical habits by means of a Finite State Machine – represented in its own ontology – using the concepts from the domain ontology. Sequences of recognized activities are then compared to the Finite State Machines associated to the different persons in a household, and assigned to the person with the most similar modelled sequence.
            """@en ;
    schema:name "Attributing recognised activities in multi-person households using ontology-based finite state machines"@en ;
    foaf:maker _:N003dd7b9fdf84347a3a4edaeff755e6a,
        _:N3c59b1bfc8c74f60b4fcc0f53a0bb97c,
        _:N92f755d8ec69429aa810dcc8d1fd0d94,
        _:Nd40d6f8d3b8b485baa65d82645bd0a5f,
        _:Ndcafa4ed27044680a470e415cca914e7,
        <file:///author/femke-ongenae>,
        <file:///author/stijn-verstichel> ;
    foaf:name "Attributing recognised activities in multi-person households using ontology-based finite state machines"@en .

<file:///publication/8550825> a schema:ScholarlyArticle,
        foaf:Document ;
    dc1:creator _:N689b2513bbee41c582f93e102e384893,
        _:N974e2778c35d4196a9e8b3f86cd4600b,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte>,
        <file:///author/stijn-verstichel> ;
    dc1:description """
                In 2013, the Flemish Government launched the Vitalink platform. This initiative focuses on the sharing of health and welfare data to support primary healthcare. In this paper, the objectives and mission of the Vitalink initiative are discussed. Security and privacy measures are reviewed, and the technical implementation of the Vitalink platform is presented. Through a case study, the possibility of interaction with cloud solutions for healthcare is also investigated upon; this was initially not the focus of Vitalink. The Vitalink initiative provides support for secure data sharing in primary healthcare, which in the long term will improve the efficiency of care and will decrease costs. Based on the results of the case study, Vitalink allowed cloud solutions or applications not providing end-to-end security to use their system. The most important lesson learned during this research was the need for firm regulations and stipulations for cloud solutions to interact with the Vitalink platform. However, these are currently still vague.
            """@en ;
    dc1:title "Sharing health data in Belgium: A home care case study using the Vitalink platform"@en ;
    schema:author _:N689b2513bbee41c582f93e102e384893,
        _:N974e2778c35d4196a9e8b3f86cd4600b,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte>,
        <file:///author/stijn-verstichel> ;
    schema:description """
                In 2013, the Flemish Government launched the Vitalink platform. This initiative focuses on the sharing of health and welfare data to support primary healthcare. In this paper, the objectives and mission of the Vitalink initiative are discussed. Security and privacy measures are reviewed, and the technical implementation of the Vitalink platform is presented. Through a case study, the possibility of interaction with cloud solutions for healthcare is also investigated upon; this was initially not the focus of Vitalink. The Vitalink initiative provides support for secure data sharing in primary healthcare, which in the long term will improve the efficiency of care and will decrease costs. Based on the results of the case study, Vitalink allowed cloud solutions or applications not providing end-to-end security to use their system. The most important lesson learned during this research was the need for firm regulations and stipulations for cloud solutions to interact with the Vitalink platform. However, these are currently still vague.
            """@en ;
    schema:name "Sharing health data in Belgium: A home care case study using the Vitalink platform"@en ;
    foaf:maker _:N689b2513bbee41c582f93e102e384893,
        _:N974e2778c35d4196a9e8b3f86cd4600b,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte>,
        <file:///author/stijn-verstichel> ;
    foaf:name "Sharing health data in Belgium: A home care case study using the Vitalink platform"@en .

<file:///publication/ONGENAE20137629> a schema:ScholarlyArticle,
        foaf:Document ;
    dc1:creator _:N1b992a3322ab4f05857d683e4fd730dc,
        _:N2acf033dbf52426792ef6f3c902ae3c0,
        _:N543f1a3eaf13404e8ec66c4b7cd89a67,
        _:N58ce7b8743da421ca225bcfc1db20d88,
        _:Na2e3f8f5f3914c72a96864fac5bfc381,
        _:Nc9330ae797a2467b92fe4d9f176ec58d,
        <file:///author/femke-ongenae> ;
    dc1:description """
                Context-aware platforms consist of dynamic algorithms that take the context information into account to adapt the behavior of the applications. The relevant context information is modeled in a context model. Recently, a trend has emerged towards capturing the context in an ontology, which formally models the concepts within a certain domain, their relations and properties.Although much research has been done on the subject, the adoption of context-aware services in healthcare is lagging behind what could be expected. The main complaint made by users is that they had to significantly alter workflow patterns to accommodate the system. When new technology is introduced, the behavior of the users changes to adapt to it. Moreover, small differences in user requirements often occur between different environments where the application is deployed. However, it is difficult to foresee these changes in workflow patterns and requirements at development time. Consequently, the context-aware applications are not tuned towards the needs of the users and they are required to change their behavior to accommodate the technology instead of the other way around.To tackle this issue, a self-learning, probabilistic, ontology-based framework is proposed, which allows context-aware applications to adapt their behavior at run-time. It exploits the context information gathered in the ontology to mine for trends and patterns in the behavior of the users. These trends are then prioritized and filtered by associating probabilities, which express their reliability. This new knowledge and their associated probabilities are then integrated into the context model and dynamic algorithms. Finally, the probabilities are in- or decreased, according to context and behavioral information gathered about the usage of the learned information.A use case is presented to illustrate the applicability of the framework, namely mining the reasons for patients’ nurse call light use to automatically launch calls. Detecting Systemic Inflammatory Response Syndrome (SIRS) as a reason for nurse calls is used as a realistic scenario to evaluate the correctness and performance of the proposed framework. It is shown that correct results are achieved when the dataset contains at least 1000 instances and the amount of noise is lower than 5%. The execution time and memory usage are also negligible for a realistic dataset, i.e., below 100 ms and 10 MB.
            """@en ;
    dc1:title "A probabilistic ontology-based platform for self-learning context-aware healthcare applications"@en ;
    schema:author _:N1b992a3322ab4f05857d683e4fd730dc,
        _:N2acf033dbf52426792ef6f3c902ae3c0,
        _:N543f1a3eaf13404e8ec66c4b7cd89a67,
        _:N58ce7b8743da421ca225bcfc1db20d88,
        _:Na2e3f8f5f3914c72a96864fac5bfc381,
        _:Nc9330ae797a2467b92fe4d9f176ec58d,
        <file:///author/femke-ongenae> ;
    schema:description """
                Context-aware platforms consist of dynamic algorithms that take the context information into account to adapt the behavior of the applications. The relevant context information is modeled in a context model. Recently, a trend has emerged towards capturing the context in an ontology, which formally models the concepts within a certain domain, their relations and properties.Although much research has been done on the subject, the adoption of context-aware services in healthcare is lagging behind what could be expected. The main complaint made by users is that they had to significantly alter workflow patterns to accommodate the system. When new technology is introduced, the behavior of the users changes to adapt to it. Moreover, small differences in user requirements often occur between different environments where the application is deployed. However, it is difficult to foresee these changes in workflow patterns and requirements at development time. Consequently, the context-aware applications are not tuned towards the needs of the users and they are required to change their behavior to accommodate the technology instead of the other way around.To tackle this issue, a self-learning, probabilistic, ontology-based framework is proposed, which allows context-aware applications to adapt their behavior at run-time. It exploits the context information gathered in the ontology to mine for trends and patterns in the behavior of the users. These trends are then prioritized and filtered by associating probabilities, which express their reliability. This new knowledge and their associated probabilities are then integrated into the context model and dynamic algorithms. Finally, the probabilities are in- or decreased, according to context and behavioral information gathered about the usage of the learned information.A use case is presented to illustrate the applicability of the framework, namely mining the reasons for patients’ nurse call light use to automatically launch calls. Detecting Systemic Inflammatory Response Syndrome (SIRS) as a reason for nurse calls is used as a realistic scenario to evaluate the correctness and performance of the proposed framework. It is shown that correct results are achieved when the dataset contains at least 1000 instances and the amount of noise is lower than 5%. The execution time and memory usage are also negligible for a realistic dataset, i.e., below 100 ms and 10 MB.
            """@en ;
    schema:name "A probabilistic ontology-based platform for self-learning context-aware healthcare applications"@en ;
    foaf:maker _:N1b992a3322ab4f05857d683e4fd730dc,
        _:N2acf033dbf52426792ef6f3c902ae3c0,
        _:N543f1a3eaf13404e8ec66c4b7cd89a67,
        _:N58ce7b8743da421ca225bcfc1db20d88,
        _:Na2e3f8f5f3914c72a96864fac5bfc381,
        _:Nc9330ae797a2467b92fe4d9f176ec58d,
        <file:///author/femke-ongenae> ;
    foaf:name "A probabilistic ontology-based platform for self-learning context-aware healthcare applications"@en .

<file:///publication/arndt_ai4health_2018> a schema:ScholarlyArticle,
        foaf:Document ;
    dc1:creator _:N07d533e32fb9462db3ef193834d018d0,
        _:N311d51f6aebf459d912b29d02a236780,
        _:Nabc9d76b368749be9f47c51dc3f93e1d,
        _:Ne511594bc7f64b5c86d61cad93ffbddf,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte> ;
    dc1:description """
                Modern developments confront us with an ever increasing amount of streaming data: different sensors in environments like hospitals or factories communicate their measurements to other applications. Having this data at disposal faces us with a new challenge: the data needs to be integrated to existing frameworks. As the availability of sensors can rapidly change, these need to be flexible enough to easily incorporate new systems without having to be explicitly configured. Semantic Web applications offer a solution for that enabling computers to ‘understand’ data. But for them the pure amount of data and different possible queries which can be performed on it can form an obstacle. This paper tackles this problem: we present a formalism to describe stream queries in the ontology context in which they might become relevant. These descriptions enable us to automatically decide based on the actual setting and the problem to be solved which and how sensors should be monitored further. This helps us to limit the streaming data taken into account for reasoning tasks and make stream reasoning more performant. We illustrate our approach on a health-care use case where different sensors are used to measure data on patients and their surrounding in a hospital.
            """@en ;
    dc1:title "SENSdesc: Connect Sensor queries and Context"@en ;
    schema:author _:N07d533e32fb9462db3ef193834d018d0,
        _:N311d51f6aebf459d912b29d02a236780,
        _:Nabc9d76b368749be9f47c51dc3f93e1d,
        _:Ne511594bc7f64b5c86d61cad93ffbddf,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte> ;
    schema:description """
                Modern developments confront us with an ever increasing amount of streaming data: different sensors in environments like hospitals or factories communicate their measurements to other applications. Having this data at disposal faces us with a new challenge: the data needs to be integrated to existing frameworks. As the availability of sensors can rapidly change, these need to be flexible enough to easily incorporate new systems without having to be explicitly configured. Semantic Web applications offer a solution for that enabling computers to ‘understand’ data. But for them the pure amount of data and different possible queries which can be performed on it can form an obstacle. This paper tackles this problem: we present a formalism to describe stream queries in the ontology context in which they might become relevant. These descriptions enable us to automatically decide based on the actual setting and the problem to be solved which and how sensors should be monitored further. This helps us to limit the streaming data taken into account for reasoning tasks and make stream reasoning more performant. We illustrate our approach on a health-care use case where different sensors are used to measure data on patients and their surrounding in a hospital.
            """@en ;
    schema:name "SENSdesc: Connect Sensor queries and Context"@en ;
    foaf:maker _:N07d533e32fb9462db3ef193834d018d0,
        _:N311d51f6aebf459d912b29d02a236780,
        _:Nabc9d76b368749be9f47c51dc3f93e1d,
        _:Ne511594bc7f64b5c86d61cad93ffbddf,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte> ;
    foaf:name "SENSdesc: Connect Sensor queries and Context"@en .

<file:///publication/bonte2017massif> a schema:ScholarlyArticle,
        foaf:Document ;
    dc1:creator _:N4c749c4df32543e3bcbed5506c3cc14e,
        _:N56650e4afdba491990016bf93768b123,
        _:N7242b31589654e90a6b6fb29eb97723b,
        _:N7d550e0a9b7d404ca969652eb5e69ac5,
        _:Na0137bd95e1148deba1de97361f04fe9,
        _:Nefbd72ee04264e23aa32f2fcb064360e,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte>,
        <file:///author/stijn-verstichel> ;
    dc1:description """
                Internet of Things (IoT), data-producing entities sense their environment and transmit these observations to a data processing platform for further analysis. Applications can have a notion of context awareness by combining this sensed data, or by processing the combined data. The processes of combining data can consist both of merging the dynamic sensed data, as well as fusing the sensed data with background and historical data. Semantics can aid in this task, as they have proven their use in data integration, knowledge exchange and reasoning. Semantic services performing reasoning on the integrated sensed data, combined with background knowledge, such as profile data, allow extracting useful information and support intelligent decision making. However, advanced reasoning on the combination of this sensed data and background knowledge is still hard to achieve. Furthermore, the collaboration between semantic services allows to reach complex decisions. The dynamic composition of such collaborative workflows that can adapt to the current context, has not received much attention yet. In this paper, we present MASSIF, a data-driven platform for the semantic annotation of and reasoning on IoT data. It allows the integration of multiple modular reasoning services that can collaborate in a flexible manner to facilitate complex decision-making processes. Data-driven workflows are enabled by letting services specify the data they would like to consume. After thorough processing, these services can decide to share their decisions with other consumers. By defining the data these services would like to consume, they can operate on a subset of data, improving reasoning efficiency. Furthermore, each of these services can integrate the consumed data with background knowledge in its own context model, for rapid intelligent decision making. To show the strengths of the platform, two use cases are detailed and thoroughly evaluated.
            """@en ;
    dc1:title "The MASSIF platform: a modular and semantic platform for the development of flexible IoT services"@en ;
    schema:author _:N4c749c4df32543e3bcbed5506c3cc14e,
        _:N56650e4afdba491990016bf93768b123,
        _:N7242b31589654e90a6b6fb29eb97723b,
        _:N7d550e0a9b7d404ca969652eb5e69ac5,
        _:Na0137bd95e1148deba1de97361f04fe9,
        _:Nefbd72ee04264e23aa32f2fcb064360e,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte>,
        <file:///author/stijn-verstichel> ;
    schema:description """
                Internet of Things (IoT), data-producing entities sense their environment and transmit these observations to a data processing platform for further analysis. Applications can have a notion of context awareness by combining this sensed data, or by processing the combined data. The processes of combining data can consist both of merging the dynamic sensed data, as well as fusing the sensed data with background and historical data. Semantics can aid in this task, as they have proven their use in data integration, knowledge exchange and reasoning. Semantic services performing reasoning on the integrated sensed data, combined with background knowledge, such as profile data, allow extracting useful information and support intelligent decision making. However, advanced reasoning on the combination of this sensed data and background knowledge is still hard to achieve. Furthermore, the collaboration between semantic services allows to reach complex decisions. The dynamic composition of such collaborative workflows that can adapt to the current context, has not received much attention yet. In this paper, we present MASSIF, a data-driven platform for the semantic annotation of and reasoning on IoT data. It allows the integration of multiple modular reasoning services that can collaborate in a flexible manner to facilitate complex decision-making processes. Data-driven workflows are enabled by letting services specify the data they would like to consume. After thorough processing, these services can decide to share their decisions with other consumers. By defining the data these services would like to consume, they can operate on a subset of data, improving reasoning efficiency. Furthermore, each of these services can integrate the consumed data with background knowledge in its own context model, for rapid intelligent decision making. To show the strengths of the platform, two use cases are detailed and thoroughly evaluated.
            """@en ;
    schema:name "The MASSIF platform: a modular and semantic platform for the development of flexible IoT services"@en ;
    foaf:maker _:N4c749c4df32543e3bcbed5506c3cc14e,
        _:N56650e4afdba491990016bf93768b123,
        _:N7242b31589654e90a6b6fb29eb97723b,
        _:N7d550e0a9b7d404ca969652eb5e69ac5,
        _:Na0137bd95e1148deba1de97361f04fe9,
        _:Nefbd72ee04264e23aa32f2fcb064360e,
        <file:///author/femke-ongenae>,
        <file:///author/pieter-bonte>,
        <file:///author/stijn-verstichel> ;
    foaf:name "The MASSIF platform: a modular and semantic platform for the development of flexible IoT services"@en .

<file:///publication/vandewiele_genesim_2016> a schema:ScholarlyArticle,
        foaf:Document ;
    dc1:creator _:N4032a6acc1f9465082472fef3ab950ae,
        _:N52180ccf893e4d41ad9a8229e0299496,
        _:Nab57fec2672b4df9a8a39315e08dd1ee,
        <file:///author/femke-ongenae>,
        <file:///author/gilles-vandewiele> ;
    dc1:description """
                Models obtained by decision tree induction techniques excel in being interpretable. However, they can be prone to overfitting, which results in a low predictive performance. Ensemble techniques are able to achieve a higher accuracy. However, this comes at a cost of losing interpretability of the resulting model. This makes ensemble techniques impractical in applications where decision support, instead of decision making, is crucial. To bridge this gap, we present the GENESIM algorithm that transforms an ensemble of decision trees to a single decision tree with an enhanced predictive performance by using a genetic algorithm. We compared GENESIM to prevalent decision tree induction and ensemble techniques using twelve publicly available data sets. The results show that GENESIM achieves a better predictive performance on most of these data sets than decision tree induction techniques and a predictive performance in the same order of magnitude as the ensemble techniques. Moreover, the resulting model of GENESIM has a very low complexity, making it very interpretable, in contrast to ensemble techniques.
            """@en ;
    dc1:title "GENESIM : genetic extraction of a single, interpretable model"@en ;
    schema:author _:N4032a6acc1f9465082472fef3ab950ae,
        _:N52180ccf893e4d41ad9a8229e0299496,
        _:Nab57fec2672b4df9a8a39315e08dd1ee,
        <file:///author/femke-ongenae>,
        <file:///author/gilles-vandewiele> ;
    schema:description """
                Models obtained by decision tree induction techniques excel in being interpretable. However, they can be prone to overfitting, which results in a low predictive performance. Ensemble techniques are able to achieve a higher accuracy. However, this comes at a cost of losing interpretability of the resulting model. This makes ensemble techniques impractical in applications where decision support, instead of decision making, is crucial. To bridge this gap, we present the GENESIM algorithm that transforms an ensemble of decision trees to a single decision tree with an enhanced predictive performance by using a genetic algorithm. We compared GENESIM to prevalent decision tree induction and ensemble techniques using twelve publicly available data sets. The results show that GENESIM achieves a better predictive performance on most of these data sets than decision tree induction techniques and a predictive performance in the same order of magnitude as the ensemble techniques. Moreover, the resulting model of GENESIM has a very low complexity, making it very interpretable, in contrast to ensemble techniques.
            """@en ;
    schema:name "GENESIM : genetic extraction of a single, interpretable model"@en ;
    foaf:maker _:N4032a6acc1f9465082472fef3ab950ae,
        _:N52180ccf893e4d41ad9a8229e0299496,
        _:Nab57fec2672b4df9a8a39315e08dd1ee,
        <file:///author/femke-ongenae>,
        <file:///author/gilles-vandewiele> ;
    foaf:name "GENESIM : genetic extraction of a single, interpretable model"@en .

<https://dx.doi.org/10.1007/s10619-017-7211-3> a schema:ScholarlyArticle,
        foaf:Document ;
    dc1:creator <https://data.verborgh.org/people/io_taxidou>,
        <https://data.verborgh.org/people/peter_fischer>,
        <https://data.verborgh.org/people/tom_de_nies>,
        <https://ruben.verborgh.org/profile/#me>,
        <https://sven-lieber.org/profile#me> ;
    dc1:description """
                Fast, massive, and viral data diffused on social media affects a large share of the online population, and thus, the (prospective) information diffusion mechanisms behind it are of great interest to researchers. The (retrospective) provenance of such data is equally important because it contributes to the understanding of the relevance and trustworthiness of the information. Furthermore, computing provenance in a timely way is crucial for particular use cases and practitioners, such as online journalists that promptly need to assess particular pieces of information. Social media currently provide insufficient mechanisms for provenance tracking, publication and generation, while state-of-the-art on social media research focuses mainly on explicit diffusion mechanisms (like retweets in Twitter or reshares in Facebook).The implicit diffusion mechanisms remain understudied due to the difficulties of being captured and properly understood. From a technical side, the state of the art for provenance reconstruction evaluates small datasets after the fact, sidestepping requirements for scale and speed of current social media data. In this paper, we investigate the mechanisms of implicit information diffusion by computing its fine-grained provenance. We prove that explicit mechanisms are insufficient to capture influence and our analysis unravels a significant part of implicit interactions and influence in social media. Our approach works incrementally and can be scaled up to cover a truly Web-scale scenario like major events. The results show that (on a single machine) we can process datasets consisting of up to several millions of messages at rates that cover bursty behaviour, without compromising result quality. By doing that, we provide to online journalists and social media users in general, fine grained provenance reconstruction which sheds lights on implicit interactions not captured by social media providers. These results are provided in an online fashion which also allows for fast relevance and trustworthiness assessment."""@en ;
    dc1:title "Web-scale Provenance Reconstruction of Implicit Information Diffusion on Social Media"@en ;
    bibo:issue 1 ;
    bibo:pageEnd 79 ;
    bibo:pageStart 47 ;
    bibo:volume 36 ;
    sioc:topic <http://dbpedia.org/resource/Facebook>,
        <http://dbpedia.org/resource/Provenance>,
        <http://dbpedia.org/resource/Research>,
        <http://dbpedia.org/resource/Social_media>,
        <http://dbpedia.org/resource/World_Wide_Web>,
        <https://data.verborgh.org/topics/information_diffusion>,
        <https://data.verborgh.org/topics/publication> ;
    schema:about <http://dbpedia.org/resource/Facebook>,
        <http://dbpedia.org/resource/Provenance>,
        <http://dbpedia.org/resource/Research>,
        <http://dbpedia.org/resource/Social_media>,
        <http://dbpedia.org/resource/World_Wide_Web>,
        <https://data.verborgh.org/topics/information_diffusion>,
        <https://data.verborgh.org/topics/publication> ;
    schema:author <https://data.verborgh.org/people/io_taxidou>,
        <https://data.verborgh.org/people/peter_fischer>,
        <https://data.verborgh.org/people/tom_de_nies>,
        <https://ruben.verborgh.org/profile/#me>,
        <https://sven-lieber.org/profile#me> ;
    schema:description """
                Fast, massive, and viral data diffused on social media affects a large share of the online population, and thus, the (prospective) information diffusion mechanisms behind it are of great interest to researchers. The (retrospective) provenance of such data is equally important because it contributes to the understanding of the relevance and trustworthiness of the information. Furthermore, computing provenance in a timely way is crucial for particular use cases and practitioners, such as online journalists that promptly need to assess particular pieces of information. Social media currently provide insufficient mechanisms for provenance tracking, publication and generation, while state-of-the-art on social media research focuses mainly on explicit diffusion mechanisms (like retweets in Twitter or reshares in Facebook).The implicit diffusion mechanisms remain understudied due to the difficulties of being captured and properly understood. From a technical side, the state of the art for provenance reconstruction evaluates small datasets after the fact, sidestepping requirements for scale and speed of current social media data. In this paper, we investigate the mechanisms of implicit information diffusion by computing its fine-grained provenance. We prove that explicit mechanisms are insufficient to capture influence and our analysis unravels a significant part of implicit interactions and influence in social media. Our approach works incrementally and can be scaled up to cover a truly Web-scale scenario like major events. The results show that (on a single machine) we can process datasets consisting of up to several millions of messages at rates that cover bursty behaviour, without compromising result quality. By doing that, we provide to online journalists and social media users in general, fine grained provenance reconstruction which sheds lights on implicit interactions not captured by social media providers. These results are provided in an online fashion which also allows for fast relevance and trustworthiness assessment."""@en ;
    schema:name "Web-scale Provenance Reconstruction of Implicit Information Diffusion on Social Media"@en ;
    foaf:maker <https://data.verborgh.org/people/io_taxidou>,
        <https://data.verborgh.org/people/peter_fischer>,
        <https://data.verborgh.org/people/tom_de_nies>,
        <https://ruben.verborgh.org/profile/#me>,
        <https://sven-lieber.org/profile#me> ;
    foaf:name "Web-scale Provenance Reconstruction of Implicit Information Diffusion on Social Media"@en ;
    foaf:topic <http://dbpedia.org/resource/Facebook>,
        <http://dbpedia.org/resource/Provenance>,
        <http://dbpedia.org/resource/Research>,
        <http://dbpedia.org/resource/Social_media>,
        <http://dbpedia.org/resource/World_Wide_Web>,
        <https://data.verborgh.org/topics/information_diffusion>,
        <https://data.verborgh.org/topics/publication> .

<file:///author/gilles-vandewiele> a schema:Person,
        foaf:Person ;
    dc1:title "Gilles Vandewiele"@en ;
    foaf:name "Gilles Vandewiele"@en .

<http://dbpedia.org/resource/Facebook> a owl:Thing ;
    rdfs:label "Facebook"@en .

<http://dbpedia.org/resource/Provenance> a owl:Thing ;
    rdfs:label "provenance"@en .

<http://dbpedia.org/resource/Research> a owl:Thing ;
    rdfs:label "research"@en .

<http://dbpedia.org/resource/Social_media> a owl:Thing ;
    rdfs:label "social media"@en .

<http://dbpedia.org/resource/World_Wide_Web> a owl:Thing ;
    rdfs:label "Web"@en .

<https://data.verborgh.org/people/io_taxidou> a schema:Person,
        foaf:Person ;
    dc1:title "Io Taxidou"@en ;
    foaf:familyName "Taxidou"@en ;
    foaf:givenName "Io"@en ;
    foaf:name "Io Taxidou"@en .

<https://data.verborgh.org/people/peter_fischer> a schema:Person,
        foaf:Person ;
    dc1:title "Peter Fischer"@en ;
    foaf:familyName "Fischer"@en ;
    foaf:givenName "Peter"@en ;
    foaf:name "Peter Fischer"@en .

<https://data.verborgh.org/people/tom_de_nies> a schema:Person,
        foaf:Person ;
    dc1:title "Tom De Nies"@en ;
    foaf:familyName "De Nies"@en ;
    foaf:givenName "Tom"@en ;
    foaf:name "Tom De Nies"@en .

<https://data.verborgh.org/topics/information_diffusion> a owl:Thing ;
    rdfs:label "information diffusion"@en .

<https://data.verborgh.org/topics/publication> a owl:Thing ;
    rdfs:label "publication"@en .

<https://sven-lieber.org/profile#me> a schema:Person,
        foaf:Person ;
    dc1:title "Sven Lieber"@en ;
    foaf:familyName "Lieber"@en ;
    foaf:givenName "Sven"@en ;
    foaf:name "Sven Lieber"@en .

<file:///> a schema:WebSite .

<https://ruben.verborgh.org/profile/#me> a schema:Person,
        foaf:Person ;
    dc1:title "Ruben Verborgh"@en ;
    schema:familyName "Verborgh"@en ;
    schema:givenName "Ruben"@en ;
    schema:name "Ruben Verborgh"@en ;
    foaf:account <https://github.com/RubenVerborgh/>,
        <https://www.linkedin.com/in/rubenverborgh> ;
    foaf:familyName "Verborgh"@en ;
    foaf:givenName "Ruben"@en ;
    foaf:name "Ruben Verborgh"@en .

<file:///author/pieter-bonte> a schema:Person,
        foaf:Person ;
    dc1:title "Pieter Bonte"@en ;
    foaf:name "Pieter Bonte"@en .

<file:///author/stijn-verstichel> a schema:Person,
        foaf:Person ;
    dc1:title "Stijn Verstichel"@en ;
    foaf:name "Stijn Verstichel"@en .

<file:///author/femke-ongenae> a schema:Person,
        foaf:Person ;
    dc1:title "Femke Ongenae"@en ;
    foaf:name "Femke Ongenae"@en .

_:N003dd7b9fdf84347a3a4edaeff755e6a a schema:Person,
        foaf:Person ;
    dc1:title "T. Tourwé"@en ;
    foaf:name "T. Tourwé"@en .

_:N07d533e32fb9462db3ef193834d018d0 a schema:Person,
        foaf:Person ;
    dc1:title "Dörthe Arndt"@en ;
    foaf:name "Dörthe Arndt"@en .

_:N1b992a3322ab4f05857d683e4fd730dc a schema:Person,
        foaf:Person ;
    dc1:title "Maxim Claeys"@en ;
    foaf:name "Maxim Claeys"@en .

_:N2acf033dbf52426792ef6f3c902ae3c0 a schema:Person,
        foaf:Person ;
    dc1:title "Thomas Dupont"@en ;
    foaf:name "Thomas Dupont"@en .

_:N311d51f6aebf459d912b29d02a236780 a schema:Person,
        foaf:Person ;
    dc1:title "Filip De Turck"@en ;
    foaf:name "Filip De Turck"@en .

_:N3c59b1bfc8c74f60b4fcc0f53a0bb97c a schema:Person,
        foaf:Person ;
    dc1:title "Bruno Volckaert"@en ;
    foaf:name "Bruno Volckaert"@en .

_:N4032a6acc1f9465082472fef3ab950ae a schema:Person,
        foaf:Person ;
    dc1:title "Sofie Van Hoecke"@en ;
    foaf:name "Sofie Van Hoecke"@en .

_:N4c749c4df32543e3bcbed5506c3cc14e a schema:Person,
        foaf:Person ;
    dc1:title "Dörthe Arndt"@en ;
    foaf:name "Dörthe Arndt"@en .

_:N52180ccf893e4d41ad9a8229e0299496 a schema:Person,
        foaf:Person ;
    dc1:title "Filip De Turck"@en ;
    foaf:name "Filip De Turck"@en .

_:N543f1a3eaf13404e8ec66c4b7cd89a67 a schema:Person,
        foaf:Person ;
    dc1:title "Wannes Kerckhove"@en ;
    foaf:name "Wannes Kerckhove"@en .

_:N56650e4afdba491990016bf93768b123 a schema:Person,
        foaf:Person ;
    dc1:title "Jeroen Schaballie"@en ;
    foaf:name "Jeroen Schaballie"@en .

_:N58ce7b8743da421ca225bcfc1db20d88 a schema:Person,
        foaf:Person ;
    dc1:title "Piet Verhoeve"@en ;
    foaf:name "Piet Verhoeve"@en .

_:N689b2513bbee41c582f93e102e384893 a schema:Person,
        foaf:Person ;
    dc1:title "Femke De Backere"@en ;
    foaf:name "Femke De Backere"@en .

_:N7242b31589654e90a6b6fb29eb97723b a schema:Person,
        foaf:Person ;
    dc1:title "Erik Mannens"@en ;
    foaf:name "Erik Mannens"@en .

_:N7d550e0a9b7d404ca969652eb5e69ac5 a schema:Person,
        foaf:Person ;
    dc1:title "Femke De Backere"@en ;
    foaf:name "Femke De Backere"@en .

_:N92f755d8ec69429aa810dcc8d1fd0d94 a schema:Person,
        foaf:Person ;
    dc1:title "E. Tsiporkova"@en ;
    foaf:name "E. Tsiporkova"@en .

_:N974e2778c35d4196a9e8b3f86cd4600b a schema:Person,
        foaf:Person ;
    dc1:title "Filip De Turck"@en ;
    foaf:name "Filip De Turck"@en .

_:Na0137bd95e1148deba1de97361f04fe9 a schema:Person,
        foaf:Person ;
    dc1:title "Filip De Turck"@en ;
    foaf:name "Filip De Turck"@en .

_:Na2e3f8f5f3914c72a96864fac5bfc381 a schema:Person,
        foaf:Person ;
    dc1:title "Tom Dhaene"@en ;
    foaf:name "Tom Dhaene"@en .

_:Nab57fec2672b4df9a8a39315e08dd1ee a schema:Person,
        foaf:Person ;
    dc1:title "Olivier Janssens"@en ;
    foaf:name "Olivier Janssens"@en .

_:Nabc9d76b368749be9f47c51dc3f93e1d a schema:Person,
        foaf:Person ;
    dc1:title "Alexander Dejonghe"@en ;
    foaf:name "Alexander Dejonghe"@en .

_:Nc9330ae797a2467b92fe4d9f176ec58d a schema:Person,
        foaf:Person ;
    dc1:title "Filip De Turck"@en ;
    foaf:name "Filip De Turck"@en .

_:Nd40d6f8d3b8b485baa65d82645bd0a5f a schema:Person,
        foaf:Person ;
    dc1:title "Jelle Nelis"@en ;
    foaf:name "Jelle Nelis"@en .

_:Ndcafa4ed27044680a470e415cca914e7 a schema:Person,
        foaf:Person ;
    dc1:title "N. Gonzalez-Deleito"@en ;
    foaf:name "N. Gonzalez-Deleito"@en .

_:Ne511594bc7f64b5c86d61cad93ffbddf a schema:Person,
        foaf:Person ;
    dc1:title "Ruben Verborgh"@en ;
    foaf:name "Ruben Verborgh"@en .

_:Nefbd72ee04264e23aa32f2fcb064360e a schema:Person,
        foaf:Person ;
    dc1:title "Rik Van de Walle"@en ;
    foaf:name "Rik Van de Walle"@en .

